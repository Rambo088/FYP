{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rambo088/FYP/blob/FYP-SourceCode-FinalVersion/TrafficPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5xLq22Dk4-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6ebbfe-38cc-4bce-af28-16ce5882c4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from gplearn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gplearn) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.4.0)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gplearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "qujbxPy2kdSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l_fVufBlEFB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dropout, Dense\n",
        "from keras import callbacks\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt8SAQEjlseI"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"traffic.csv\")\n",
        "data.head()\n",
        "\n",
        "data[\"DateTime\"]= pd.to_datetime(data[\"DateTime\"])\n",
        "\n",
        "# dropping the ID column since its not needed\n",
        "data = data.drop([\"ID\"], axis=1)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9guFIpDmK2-"
      },
      "outputs": [],
      "source": [
        "# Creating a copy for EDA\n",
        "eda_data = data.copy()\n",
        "\n",
        "# Plotting Time Series\n",
        "colors = [\"#FF0000\", \"#0006FF\", \"#1DFF00\", \"#FAFF00\"]\n",
        "plt.figure(figsize=(25, 8), facecolor=\"#99ccff\")\n",
        "time_series_plot = sns.lineplot(x=eda_data['DateTime'], y=\"Vehicles\", data=eda_data, hue=\"Junction\", palette=colors)\n",
        "time_series_plot.set_title(\"Each Junction's Traffic Over The Years\")\n",
        "time_series_plot.set_xlabel(\"Date\")\n",
        "time_series_plot.set_ylabel(\"Number of Vehicles\")\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckjU2BWlnmRA"
      },
      "outputs": [],
      "source": [
        "eda_data[\"Year\"]= eda_data['DateTime'].dt.year\n",
        "eda_data[\"Month\"]= eda_data['DateTime'].dt.month\n",
        "eda_data[\"Date_no\"]= eda_data['DateTime'].dt.day\n",
        "eda_data[\"Day\"]= eda_data.DateTime.dt.strftime(\"%A\")\n",
        "eda_data[\"Hour\"]= eda_data['DateTime'].dt.hour\n",
        "\n",
        "eda_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W9yos3-iIBs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "traffic_data_resampled = data.set_index('DateTime').resample('D').mean()\n",
        "sns.lineplot(data=traffic_data_resampled, x=traffic_data_resampled.index, y='Vehicles')\n",
        "plt.title('Traffic Volume Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Vehicles')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKFZ8hJsw7UE"
      },
      "outputs": [],
      "source": [
        "# Plotting the new columns\n",
        "new_features = [ \"Year\",\"Month\", \"Day\", \"Hour\"]\n",
        "\n",
        "for i in new_features:\n",
        "    plt.figure(figsize=(12,3),facecolor=\"#627D78\")\n",
        "    ax=sns.lineplot(x=eda_data[i],y=\"Vehicles\",data=eda_data, hue=\"Junction\", palette=colors )\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbIdvXVUZ2OY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620bb079-aaaa-44a3-ebc3-b8de4c8a2bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance on Test Set: 45.57%\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'Vehicles' is the target column\n",
        "X = data.drop(['DateTime', 'Vehicles'], axis=1).values\n",
        "y = data['Vehicles'].values.reshape(-1, 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# Define a simple neural network for regression\n",
        "class SimpleRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleRegressionModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = X_train.shape[1]\n",
        "model = SimpleRegressionModel(input_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Make predictions on the test set\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_tensor).numpy()\n",
        "\n",
        "# Calculate modelPerformance as a percentage\n",
        "modelPerformanceReLU = 100 - mean_squared_error(y_test, predictions) * 100 / np.var(y_test)\n",
        "\n",
        "print(f'Model Performance on Test Set: {modelPerformanceReLU:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_c4HFYihaUj"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a dataframe 'data' with features and target variable\n",
        "# Replace 'YOUR_TARGET_COLUMN' with the actual name of your target column\n",
        "X = data.drop(['DateTime'], axis=1).values\n",
        "y = data['Vehicles'].values.reshape(-1, 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# Define a GRU model for symbolic regression\n",
        "class SymbolicRegressionGRU(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SymbolicRegressionGRU, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size=50, num_layers=2, batch_first=True)\n",
        "        self.fc = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = X_train.shape[1]\n",
        "model = SymbolicRegressionGRU(input_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train_tensor.unsqueeze(1))\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Make predictions on the test set\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_tensor.unsqueeze(1)).numpy()\n",
        "\n",
        "# Calculate accuracy as a percentage\n",
        "modelPerformanceGRU = 100 - mean_squared_error(y_test, predictions) * 100 / np.var(y_test)\n",
        "print(f'Model Performance on Test Set: {modelPerformanceGRU:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create separate dataframes for each junction\n",
        "junction_1_data = data[data['Junction'] == 1].copy()\n",
        "junction_2_data = data[data['Junction'] == 2].copy()\n",
        "junction_3_data = data[data['Junction'] == 3].copy()\n",
        "junction_4_data = data[data['Junction'] == 4].copy()\n",
        "\n",
        "# Plotting Time Series for each junction\n",
        "colors = [\"#FF0000\", \"#0006FF\", \"#1DFF00\", \"#FAFF00\"]\n",
        "plt.figure(figsize=(25, 8), facecolor=\"#99ccff\")\n",
        "\n",
        "# Plot for Junction 1\n",
        "plt.subplot(411)\n",
        "sns.lineplot(x=junction_1_data['DateTime'], y=\"Vehicles\", data=junction_1_data, color=colors[0])\n",
        "plt.title(\"Junction 1 Traffic Over The Years\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Vehicles\")\n",
        "\n",
        "# Plot for Junction 2\n",
        "plt.subplot(412)\n",
        "sns.lineplot(x=junction_2_data['DateTime'], y=\"Vehicles\", data=junction_2_data, color=colors[1])\n",
        "plt.title(\"Junction 2 Traffic Over The Years\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Vehicles\")\n",
        "\n",
        "# Plot for Junction 3\n",
        "plt.subplot(413)\n",
        "sns.lineplot(x=junction_3_data['DateTime'], y=\"Vehicles\", data=junction_3_data, color=colors[2])\n",
        "plt.title(\"Junction 3 Traffic Over The Years\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Vehicles\")\n",
        "\n",
        "# Plot for Junction 4\n",
        "plt.subplot(414)\n",
        "sns.lineplot(x=junction_4_data['DateTime'], y=\"Vehicles\", data=junction_4_data, color=colors[3])\n",
        "plt.title(\"Junction 4 Traffic Over The Years\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Vehicles\")\n",
        "\n",
        "# Adjust layout for better visualization\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W076qSoxCUdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from the XLSX file\n",
        "df = pd.read_excel('ModelTests.xlsx')\n",
        "\n",
        "# Plotting the line graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Test'], df['ReLU'], marker='o', label='ReLU')\n",
        "plt.plot(df['Test'], df['GRU'], marker='o', label='GRU')\n",
        "\n",
        "# Set y-axis limits\n",
        "plt.ylim(40, 80)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Test')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Comparison of ReLU and GRU Models')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2QWe6UKIHV-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data=eda_data, hue= \"Junction\",palette=colors)"
      ],
      "metadata": {
        "id": "iRJw6DRBg3GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_Junction = data.pivot(columns=\"Junction\", index=\"DateTime\")\n",
        "data_Junction.describe()\n",
        "\n",
        "#Creating new sets\n",
        "data_1 = data_Junction[[('Vehicles', 1)]]\n",
        "data_2 = data_Junction[[('Vehicles', 2)]]\n",
        "data_3 = data_Junction[[('Vehicles', 3)]]\n",
        "data_4 = data_Junction[[('Vehicles', 4)]]\n",
        "data_4 = data_4.dropna() #Junction 4 has limited data only for a few months\n",
        "\n",
        "#Dropping level one in dfs's index as it is a multi index data frame\n",
        "list_dfs = [data_1, data_2, data_3, data_4]\n",
        "for i in list_dfs:\n",
        "    i.columns= i.columns.droplevel(level=1)\n",
        "\n",
        "def Sub_Plots4(data_1, data_2, data_3, data_4,title):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(15, 8),facecolor=\"#99ccff\", sharey=True)\n",
        "    fig.suptitle(title)\n",
        "    #J1\n",
        "    pl_1=sns.lineplot(ax=axes[0],data=data_1,color=colors[0])\n",
        "    #pl_1=plt.ylabel()\n",
        "    axes[0].set(ylabel =\"Junction 1\")\n",
        "    #J2\n",
        "    pl_2=sns.lineplot(ax=axes[1],data=data_2,color=colors[1])\n",
        "    axes[1].set(ylabel =\"Junction 2\")\n",
        "    #J3\n",
        "    pl_3=sns.lineplot(ax=axes[2],data=data_3,color=colors[2])\n",
        "    axes[2].set(ylabel =\"Junction 3\")\n",
        "    #J4\n",
        "    pl_4=sns.lineplot(ax=axes[3],data=data_4,color=colors[3])\n",
        "    axes[3].set(ylabel =\"Junction 4\")\n",
        "\n",
        "\n",
        "#Plotting the dataframe to check for stationarity\n",
        "Sub_Plots4(data_1.Vehicles, data_2.Vehicles,data_3.Vehicles,data_4.Vehicles,\"Dataframes Before Transformation\")"
      ],
      "metadata": {
        "id": "tIhuNWhfsjD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to normalize data\n",
        "def normalize_data(data, column):\n",
        "    avg = data[column].mean()\n",
        "    std_dev = data[column].std()\n",
        "    normalized_data = (data[column] - avg) / std_dev\n",
        "    normalized_data = normalized_data.to_frame()\n",
        "    return normalized_data, avg, std_dev\n",
        "\n",
        "# Function to difference data\n",
        "def difference_data(data, column, interval):\n",
        "    differences = []\n",
        "    for i in range(interval, len(data)):\n",
        "        diff_value = data[column][i] - data[column][i - interval]\n",
        "        differences.append(diff_value)\n",
        "    return differences\n",
        "\n",
        "# Normalizing and differencing to make the series stationary\n",
        "df1_norm, avg_junction1, std_dev_junction1 = normalize_data(data_1, \"Vehicles\")\n",
        "diff_junction1 = difference_data(df1_norm, column=\"Vehicles\", interval=(24*7))  # Weekly difference\n",
        "df1_norm = df1_norm[24*7:]\n",
        "df1_norm.columns = [\"Normalized\"]\n",
        "df1_norm[\"Difference\"] = diff_junction1\n",
        "\n",
        "df2_norm, avg_junction2, std_dev_junction2 = normalize_data(data_2, \"Vehicles\")\n",
        "diff_junction2 = difference_data(df2_norm, column=\"Vehicles\", interval=(24))  # Daily difference\n",
        "df2_norm = df2_norm[24:]\n",
        "df2_norm.columns = [\"Normalized\"]\n",
        "df2_norm[\"Difference\"] = diff_junction2\n",
        "\n",
        "df3_norm, avg_junction3, std_dev_junction3 = normalize_data(data_3, \"Vehicles\")\n",
        "diff_junction3 = difference_data(df3_norm, column=\"Vehicles\", interval=1)  # Hourly difference\n",
        "df3_norm = df3_norm[1:]\n",
        "df3_norm.columns = [\"Normalized\"]\n",
        "df3_norm[\"Difference\"] = diff_junction3\n",
        "\n",
        "df4_norm, avg_junction4, std_dev_junction4 = normalize_data(data_4, \"Vehicles\")\n",
        "diff_junction4 = difference_data(df4_norm, column=\"Vehicles\", interval=1)  # Hourly difference\n",
        "df4_norm = df4_norm[1:]\n",
        "df4_norm.columns = [\"Normalized\"]\n",
        "df4_norm[\"Difference\"] = diff_junction4\n",
        "\n",
        "Sub_Plots4(df1_norm.Difference, df2_norm.Difference,df3_norm.Difference,df4_norm.Difference,\"Dataframes After Transformation\")\n"
      ],
      "metadata": {
        "id": "kuwSoEhjB2aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Data for Each Junction\n",
        "data_J1 = df1_norm[\"Difference\"].dropna().to_frame()\n",
        "data_J2 = df2_norm[\"Difference\"].dropna().to_frame()\n",
        "data_J3 = df3_norm[\"Difference\"].dropna().to_frame()\n",
        "data_J4 = df4_norm[\"Difference\"].dropna().to_frame()\n",
        "\n",
        "# Function to split dataset\n",
        "def split_data(df):\n",
        "    train_size = int(len(df) * 0.90)\n",
        "    train, test = df[:train_size], df[train_size:]\n",
        "    return train, test\n",
        "\n",
        "# Splitting the training and test datasets for each junction\n",
        "Junction1_train, Junction1_test = split_data(data_J1)\n",
        "Junction2_train, Junction2_test = split_data(data_J2)\n",
        "Junction3_train, Junction3_test = split_data(data_J3)\n",
        "Junction4_train, Junction4_test = split_data(data_J4)\n",
        "\n",
        "# Function to create features and targets\n",
        "def create_features_targets(df):\n",
        "    X, y = [], []\n",
        "    steps = 32\n",
        "    for i in range(steps, len(df)):\n",
        "        X.append(df[i - steps:i].values)\n",
        "        y.append(df.iloc[i].values)\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X, y\n",
        "\n",
        "# Function to fix feature shape\n",
        "def fix_feature_shape(train, test):\n",
        "    train = np.reshape(train, (train.shape[0], train.shape[1], 1))\n",
        "    test = np.reshape(test, (test.shape[0], test.shape[1], 1))\n",
        "    return train, test\n",
        "\n",
        "# Assigning features and target for each junction\n",
        "X_trainJ1, y_trainJ1 = create_features_targets(Junction1_train)\n",
        "X_testJ1, y_testJ1 = create_features_targets(Junction1_test)\n",
        "X_trainJ1, X_testJ1 = fix_feature_shape(X_trainJ1, X_testJ1)\n",
        "\n",
        "X_trainJ2, y_trainJ2 = create_features_targets(Junction2_train)\n",
        "X_testJ2, y_testJ2 = create_features_targets(Junction2_test)\n",
        "X_trainJ2, X_testJ2 = fix_feature_shape(X_trainJ2, X_testJ2)\n",
        "\n",
        "X_trainJ3, y_trainJ3 = create_features_targets(Junction3_train)\n",
        "X_testJ3, y_testJ3 = create_features_targets(Junction3_test)\n",
        "X_trainJ3, X_testJ3 = fix_feature_shape(X_trainJ3, X_testJ3)\n",
        "\n",
        "X_trainJ4, y_trainJ4 = create_features_targets(Junction4_train)\n",
        "X_testJ4, y_testJ4 = create_features_targets(Junction4_test)\n",
        "X_trainJ4, X_testJ4 = fix_feature_shape(X_trainJ4, X_testJ4)\n"
      ],
      "metadata": {
        "id": "Fvc1n-ISeUA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GRU_model(X_Train, y_Train, X_Test, y_Test):\n",
        "    #The GRU model\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units=64, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GRU(units=32, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GRU(units=16, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    #Compiling the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(X_Train,y_Train, validation_data=(X_Test, y_Test), epochs=10, batch_size=120)\n",
        "    pred_GRU= model.predict(X_Test)\n",
        "    return pred_GRU\n",
        "\n",
        "def RMSE_Value(test,predicted):\n",
        "    rmse = np.sqrt(np.mean(np.square(test - predicted)))\n",
        "    print(\"The root mean squared error is {}.\".format(rmse))\n",
        "    return rmse\n",
        "\n",
        "def PredictionsPlot(test,predicted,m):\n",
        "    plt.figure(figsize=(12,5),facecolor=\"#99ccff\")\n",
        "    plt.plot(test, color=colors[m],label=\"True Value\",alpha=0.5 )\n",
        "    plt.plot(predicted, color=\"#627D78\",label=\"Predicted Values\")\n",
        "    plt.title(\"Traffic Prediction Vs True values\")\n",
        "    plt.xlabel(\"DateTime\")\n",
        "    plt.ylabel(\"Prediction Error\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5GLJsv-BMyAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "def GRU_model(X_Train, y_Train, X_Test, y_Test):\n",
        "    early_stopping = callbacks.EarlyStopping(min_delta=0.001,patience=10, restore_best_weights=True)\n",
        "\n",
        "    #The GRU model\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units=150, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=150, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=50, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=50, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    #model.add(GRU(units=50, return_sequences=True,  input_shape=(X_Train.shape[1],1),activation='tanh'))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=50, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    #Compiling the model\n",
        "    model.compile(optimizer=SGD(learning_rate=lr_schedule, momentum=0.9),loss='mean_squared_error')\n",
        "    model.fit(X_Train,y_Train, validation_data=(X_Test, y_Test), epochs=50, batch_size=120,callbacks=[early_stopping])\n",
        "    pred_GRU= model.predict(X_Test)\n",
        "    return pred_GRU"
      ],
      "metadata": {
        "id": "5WgScBERqX6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Junction 1\n",
        "print(\"\\033[1;31;2m########------Junction 1------########\\033[0m\")\n",
        "PredJ1_GRU = GRU_model(X_trainJ1,y_trainJ1,X_testJ1, y_testJ1)\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(\"\\033[1;31;2m########------Junction 1------########\\033[0m\")\n",
        "RMSE_J1_GRU = RMSE_Value(y_testJ1, PredJ1_GRU)\n",
        "PredictionsPlot(y_testJ1, PredJ1_GRU, 0)\n",
        "\n",
        "#Junction 2\n",
        "print(\"\\033[1;31;2m########------Junction 2------########\\033[0m\")\n",
        "PredJ2_GRU = GRU_model(X_trainJ2, y_trainJ2, X_testJ2, y_testJ2)\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(\"\\033[1;31;2m########------Junction 2------########\\033[0m\")\n",
        "RMSE_J2_GRU = RMSE_Value(y_testJ2, PredJ2_GRU)\n",
        "PredictionsPlot(y_testJ2, PredJ2_GRU, 0)\n",
        "\n",
        "#Junction 3\n",
        "print(\"\\033[1;31;2m########------Junction 3------########\\033[0m\")\n",
        "PredJ3_GRU = GRU_model(X_trainJ3, y_trainJ3, X_testJ3, y_testJ3)\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(\"\\033[1;31;2m########------Junction 3------########\\033[0m\")\n",
        "RMSE_J3_GRU = RMSE_Value(y_testJ3, PredJ3_GRU)\n",
        "PredictionsPlot(y_testJ3, PredJ3_GRU, 0)\n",
        "\n",
        "#Junction 4\n",
        "print(\"\\033[1;31;2m########------Junction 4------########\\033[0m\")\n",
        "PredJ4_GRU = GRU_model(X_trainJ4, y_trainJ4, X_testJ4, y_testJ4)\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(\"\\033[1;31;2m########------Junction 4------########\\033[0m\")\n",
        "RMSE_J4_GRU = RMSE_Value(y_testJ4, PredJ4_GRU)\n",
        "PredictionsPlot(y_testJ4, PredJ4_GRU, 0)\n",
        "\n",
        "\n",
        "#--------------------\n",
        "model_names = [\"GRU\"]\n",
        "rmse_values = [RMSE_J1_GRU]\n",
        "\n",
        "model_rmse = list(zip(model_names, rmse_values))\n",
        "Results_df = pd.DataFrame(model_rmse, columns=[\"MODEL\", \"RMSE\"])\n",
        "styled_df = Results_df.style.background_gradient(cmap=\"cool\")\n",
        "\n",
        "colors = ['lightcoral']\n",
        "alpha = 0.9\n",
        "fig, ax = plt.subplots(figsize=(10, 4))  # Set the figure size (width, height)\n",
        "ax.bar(model_names, rmse_values, color=colors, alpha=alpha)\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('RMSE Value')\n",
        "ax.set_title('RMSE Value for Different Models - J1')\n",
        "plt.show()\n",
        "\n",
        "display(styled_df)\n"
      ],
      "metadata": {
        "id": "FbJ1dBDiqhWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to inverse transforms and Plot comparitive plots\n",
        "# invert differenced forecast\n",
        "def inverse_difference(last_ob, value):\n",
        "    inversed = value + last_ob\n",
        "    return inversed\n",
        "#Plotting the comparison\n",
        "def Sub_Plots2(df_1, df_2,title,m):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(18,4), sharey=True,facecolor=\"#99ccff\")\n",
        "    fig.suptitle(title)\n",
        "\n",
        "    pl_1=sns.lineplot(ax=axes[0],data=df_1,color=colors[m])\n",
        "    axes[0].set(ylabel =\"Prediction\")\n",
        "\n",
        "    pl_2=sns.lineplot(ax=axes[1],data=df_2[\"Vehicles\"],color=\"#627D78\")\n",
        "    axes[1].set(ylabel =\"Orignal\")"
      ],
      "metadata": {
        "id": "jotR5G0cDEuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invert the differenced forecast for Junction 1\n",
        "recover1 = df1_norm[\"Difference\"][-1412:-1].to_frame()\n",
        "recover1[\"Pred\"] = PredJ1_GRU\n",
        "transform_reversed_J1 = inverse_difference(recover1[\"Difference\"], recover1[\"Pred\"]).to_frame()\n",
        "transform_reversed_J1.columns = [\"Pred_Normed\"]\n",
        "\n",
        "# Invert the normalization for Junction 1\n",
        "final_J1_pred = (transform_reversed_J1.values * std_dev_junction1) + avg_junction1\n",
        "transform_reversed_J1[\"Pred_Final\"] = final_J1_pred\n",
        "\n",
        "# Plotting the Predictions with originals for Junction 1\n",
        "plot_comparative_plots(transform_reversed_J1[\"Pred_Final\"], junction_1_data[-1412:-1][\"Vehicles\"], \"Predictions And Originals For Junction 1\", colors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "409f6iwIDJER",
        "outputId": "c856b9b4-c1f4-4088-827d-a6f8e69b9bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_comparative_plots' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-585364facafd>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Plotting the Predictions with originals for Junction 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplot_comparative_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_reversed_J1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pred_Final\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjunction_1_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1412\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Vehicles\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Predictions And Originals For Junction 1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_comparative_plots' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# invert the differenced forecast for Junction 1\n",
        "recover1 = df1_norm[\"Difference\"][-1412:-1].to_frame()\n",
        "recover1[\"Pred\"]= PredJ1_GRU\n",
        "transform_reversed_J1 = inverse_difference(recover1[\"Difference\"], recover1[\"Pred\"]).to_frame()\n",
        "transform_reversed_J1.columns = [\"Pred_Normed\"]\n",
        "\n",
        "#Invert the normalizeation J1\n",
        "Final_J1_Pred = (df1_norm.values* std_dev_junction1) + avg_junction1\n",
        "transform_reversed_J1[\"Pred_Final\"] = Final_J1_Pred\n",
        "\n",
        "#Plotting the Predictions with orignals\n",
        "Sub_Plots2(transform_reversed_J1[\"Pred_Final\"], df1_norm[-1412:-1],\"Pridictions And Orignals For Junction 1\", 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_UmZ3c-PLUWK",
        "outputId": "f71ecd6c-9e78-4d51-85d2-cab5d9fa710c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (14424) does not match length of index (1411)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-ea0b141626bb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Invert the normalizeation J1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mFinal_J1_Pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf1_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mstd_dev_junction1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mavg_junction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtransform_reversed_J1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pred_Final\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinal_J1_Pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Plotting the Predictions with orignals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3948\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3950\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3952\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4141\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4142\u001b[0m         \"\"\"\n\u001b[0;32m-> 4143\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4870\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4871\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (14424) does not match length of index (1411)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# invert the differenced forecast for Junction 2\n",
        "recover2 = df2_norm[\"Difference\"][-1426:-1].to_frame()\n",
        "recover2[\"Pred\"] = PredJ2_GRU\n",
        "transform_reversed_J2 = inverse_difference(recover1[\"Difference\"], recover1[\"Pred\"]).to_frame()\n",
        "transform_reversed_J2.columns = [\"Pred_Normed\"]\n",
        "\n",
        "# Invert the normalization for Junction 2\n",
        "final_J2_pred = (transform_reversed_J2.values * std_dev_junction1) + avg_junction2\n",
        "transform_reversed_J2[\"Pred_Final\"] = final_J2_pred\n",
        "\n",
        "# Plotting the Predictions with originals for Junction 1\n",
        "plot_comparative_plots(transform_reversed_J2[\"Pred_Final\"], junction_2_data[-1426:-1][\"Vehicles\"],\n",
        "                        \"Predictions And Originals For Junction 2\", colors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "uJrUKTG9DrCP",
        "outputId": "a6475f24-8523-470c-c06e-20d83d548d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_comparative_plots' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-6a0ff6f98caf>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Plotting the Predictions with originals for Junction 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m plot_comparative_plots(transform_reversed_J2[\"Pred_Final\"], junction_2_data[-1426:-1][\"Vehicles\"],\n\u001b[0m\u001b[1;32m     13\u001b[0m                         \"Predictions And Originals For Junction 2\", colors[0])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_comparative_plots' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# invert the differenced forecast for Junction 3\n",
        "recover3 = df3_norm[\"Difference\"][-1429:-1].to_frame()\n",
        "recover3[\"Pred\"] = PredJ3_GRU\n",
        "transform_reversed_J3 = inverse_difference(recover1[\"Difference\"], recover1[\"Pred\"]).to_frame()\n",
        "transform_reversed_J3.columns = [\"Pred_Normed\"]\n",
        "\n",
        "# Invert the normalization for Junction 3\n",
        "final_J3_pred = (transform_reversed_J3.values * std_dev_junction1) + avg_junction3\n",
        "transform_reversed_J3[\"Pred_Final\"] = final_J3_pred\n",
        "\n",
        "# Plotting the Predictions with originals for Junction 1\n",
        "plot_comparative_plots(transform_reversed_J3[\"Pred_Final\"], junction_3_data[-1429:-1][\"Vehicles\"],\n",
        "                        \"Predictions And Originals For Junction 3\", colors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "zHRorF3kEMFP",
        "outputId": "bff542a6-df8a-4319-9cfe-0db373ac4640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_comparative_plots' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-9d2ea0567f29>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Plotting the Predictions with originals for Junction 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m plot_comparative_plots(transform_reversed_J3[\"Pred_Final\"], junction_3_data[-1429:-1][\"Vehicles\"],\n\u001b[0m\u001b[1;32m     13\u001b[0m                         \"Predictions And Originals For Junction 3\", colors[0])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_comparative_plots' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# invert the differenced forecast for Junction 4\n",
        "recover4 = df4_norm[\"Difference\"][-404:-1].to_frame()\n",
        "recover4[\"Pred\"] = PredJ4_GRU\n",
        "transform_reversed_J4 = inverse_difference(recover1[\"Difference\"], recover1[\"Pred\"]).to_frame()\n",
        "transform_reversed_J4.columns = [\"Pred_Normed\"]\n",
        "\n",
        "# Invert the normalization for Junction 4\n",
        "final_J4_pred = (transform_reversed_J4.values * std_dev_junction1) + avg_junction4\n",
        "transform_reversed_J4[\"Pred_Final\"] = final_J4_pred\n",
        "\n",
        "# Plotting the Predictions with originals for Junction 1\n",
        "plot_comparative_plots(transform_reversed_J4[\"Pred_Final\"], junction_4_data[-404:-1][\"Vehicles\"],\n",
        "                        \"Predictions And Originals For Junction 4\", colors[0])"
      ],
      "metadata": {
        "id": "GySjiYxTEkGG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "11ab0d4e-72d6-4792-9b25-2d594e20c79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_comparative_plots' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-0262cfba84a9>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Plotting the Predictions with originals for Junction 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m plot_comparative_plots(transform_reversed_J4[\"Pred_Final\"], junction_4_data[-404:-1][\"Vehicles\"],\n\u001b[0m\u001b[1;32m     13\u001b[0m                         \"Predictions And Originals For Junction 4\", colors[0])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_comparative_plots' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def genetic_algorithm(population_size, num_generations):\n",
        "    # Initialize population\n",
        "    population = initialize_population(population_size)\n",
        "\n",
        "    for generation in range(num_generations):\n",
        "        # Evaluate population\n",
        "        fitness_values = evaluate_population(population)\n",
        "\n",
        "        # Select parents for reproduction\n",
        "        selected_parents = select_parents(population, fitness_values)\n",
        "\n",
        "        # Create offspring using crossover\n",
        "        offspring = []\n",
        "        for i in range(0, len(selected_parents), 2):\n",
        "            parent1 = selected_parents[i]\n",
        "            parent2 = selected_parents[i + 1]\n",
        "            child1, child2 = avoid_fit_segments_crossover(parent1, parent2)\n",
        "            offspring.append(child1)\n",
        "            offspring.append(child2)\n",
        "\n",
        "        # Mutate offspring\n",
        "        mutated_offspring = mutate(offspring)\n",
        "\n",
        "        # Replace population with offspring\n",
        "        population = replace_population(population, mutated_offspring)\n",
        "\n",
        "        # Optionally, you can track and print the best individual in each generation\n",
        "        best_individual = get_best_individual(population, fitness_values)\n",
        "        print(f\"Generation {generation + 1}: Best Fitness = {best_individual.fitness}\")\n",
        "\n",
        "    # After all generations, return the best individual found\n",
        "    best_individual = get_best_individual(population, fitness_values)\n",
        "    return best_individual"
      ],
      "metadata": {
        "id": "kRAXrXJRe0QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_population(population_size):\n",
        "    # Create an initial population of individuals\n",
        "    population = []\n",
        "    for _ in range(population_size):\n",
        "        individual = create_individual()  # Define create_individual function based on your problem\n",
        "        population.append(individual)\n",
        "    return population"
      ],
      "metadata": {
        "id": "wWEw9kBAe2nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_population(population):\n",
        "    # Evaluate the fitness of each individual in the population\n",
        "    fitness_values = []\n",
        "    for individual in population:\n",
        "        fitness = evaluate_individual(individual)  # Define evaluate_individual function based on your problem\n",
        "        fitness_values.append(fitness)\n",
        "    return fitness_values"
      ],
      "metadata": {
        "id": "ExmCYShBe4bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_parents(population, fitness_values):\n",
        "    # Select parents for reproduction based on their fitness\n",
        "    selected_parents = []\n",
        "    total_fitness = sum(fitness_values)\n",
        "    probabilities = [fitness / total_fitness for fitness in fitness_values]\n",
        "    for _ in range(len(population) // 2):\n",
        "        parent1 = random.choices(population, weights=probabilities)[0]\n",
        "        parent2 = random.choices(population, weights=probabilities)[0]\n",
        "        selected_parents.append(parent1)\n",
        "        selected_parents.append(parent2)\n",
        "    return selected_parents"
      ],
      "metadata": {
        "id": "5zIexTe7e6Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avoid_fit_segments_crossover(parent1, parent2):\n",
        "    # Perform crossover to create offspring, avoiding fit segments\n",
        "    # Define your crossover strategy based on your problem and the avoid_fit_segments_crossover function\n",
        "    child1, child2 = crossover(parent1, parent2)  # Implement your crossover function\n",
        "    return child1, child2"
      ],
      "metadata": {
        "id": "aBDJ1syee79l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate(offspring):\n",
        "    # Optionally, apply mutation to introduce diversity into the population\n",
        "    mutated_offspring = []\n",
        "    for individual in offspring:\n",
        "        mutated_individual = apply_mutation(individual)  # Define apply_mutation function based on your problem\n",
        "        mutated_offspring.append(mutated_individual)\n",
        "    return mutated_offspring"
      ],
      "metadata": {
        "id": "0szHmaWle9np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_population(population, offspring):\n",
        "    # Replace some individuals in the population with the offspring\n",
        "    # You can use different replacement strategies like elitism, age-based replacement, etc.\n",
        "    # Implement the replacement strategy based on your problem and the current population and offspring\n",
        "    new_population = elite_selection(population, offspring)  # Define elite_selection function based on your problem\n",
        "    return new_population"
      ],
      "metadata": {
        "id": "BLyoMmfie_Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set your genetic algorithm parameters\n",
        "    population_size = 100\n",
        "    num_generations = 50\n",
        "\n",
        "    # Run the genetic algorithm\n",
        "    best_individual = genetic_algorithm(population_size, num_generations)\n",
        "\n",
        "    # Optionally, you can use the best individual found for further analysis or applications\n",
        "    print(\"Best Individual:\", best_individual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3GfevTXlfBTT",
        "outputId": "4b28a20c-b24c-4bb4-834e-64fe51e2925c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'create_individual' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-89d1a8bc6b28>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Run the genetic algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbest_individual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_generations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Optionally, you can use the best individual found for further analysis or applications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-356a97b83607>\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(population_size, num_generations)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_generations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Initialize population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-c8b7348bed2b>\u001b[0m in \u001b[0;36minitialize_population\u001b[0;34m(population_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mindividual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_individual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Define create_individual function based on your problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpopulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_individual' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJuHkQ3CI+rpEhg/nRj0ss",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}